{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('goodnotes_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalCount: 679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_selftext</th>\n",
       "      <th>submission_link_flair_text</th>\n",
       "      <th>reply_body</th>\n",
       "      <th>all_text</th>\n",
       "      <th>reply_body_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aglcrj</td>\n",
       "      <td>Goodnotes 4 vs. Goodnotes 5 right now</td>\n",
       "      <td>I have used Goodnotes 4 for work a ton.  And I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"I'm getting a ton of bugs with 5 as well (sn...</td>\n",
       "      <td>Goodnotes 4 vs. Goodnotes 5 right nowI have us...</td>\n",
       "      <td>[I'm getting a ton of bugs with 5 as well (sna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agoowm</td>\n",
       "      <td>The bundle is available !</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Thank you. I have been waiting!\\n\\n&amp;amp;#x20...</td>\n",
       "      <td>The bundle is available !The bundle is availab...</td>\n",
       "      <td>[Thank you. I have been waiting!\\n\\n&amp;amp;#x200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agprta</td>\n",
       "      <td>Finally... GoodNotes 5! Did I miss anything in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Review</td>\n",
       "      <td>['Man i imagined you would be a lot more popul...</td>\n",
       "      <td>Finally... GoodNotes 5! Did I miss anything in...</td>\n",
       "      <td>[Man i imagined you would be a lot more popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agpzxb</td>\n",
       "      <td>What happened to the pen (Goodnotes 5)?</td>\n",
       "      <td>I just got Goodnotes 5 and I was so excited fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Have you tried the ball pen? That was the cl...</td>\n",
       "      <td>What happened to the pen (Goodnotes 5)?I just ...</td>\n",
       "      <td>[Have you tried the ball pen? That was the clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agq8qv</td>\n",
       "      <td>Non Apple Pencil styluses on GOodnotes 5?</td>\n",
       "      <td>I've been using a Wacom Bamboo stylus with Goo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['According to the [review at Macstories](http...</td>\n",
       "      <td>Non Apple Pencil styluses on GOodnotes 5?I've ...</td>\n",
       "      <td>[According to the [review at Macstories](https...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission_id                                   submission_title  \\\n",
       "0        aglcrj              Goodnotes 4 vs. Goodnotes 5 right now   \n",
       "1        agoowm                          The bundle is available !   \n",
       "2        agprta  Finally... GoodNotes 5! Did I miss anything in...   \n",
       "3        agpzxb            What happened to the pen (Goodnotes 5)?   \n",
       "4        agq8qv          Non Apple Pencil styluses on GOodnotes 5?   \n",
       "\n",
       "                                 submission_selftext  \\\n",
       "0  I have used Goodnotes 4 for work a ton.  And I...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  I just got Goodnotes 5 and I was so excited fo...   \n",
       "4  I've been using a Wacom Bamboo stylus with Goo...   \n",
       "\n",
       "  submission_link_flair_text  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                     Review   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "\n",
       "                                          reply_body  \\\n",
       "0  [\"I'm getting a ton of bugs with 5 as well (sn...   \n",
       "1  ['Thank you. I have been waiting!\\n\\n&amp;#x20...   \n",
       "2  ['Man i imagined you would be a lot more popul...   \n",
       "3  [\"Have you tried the ball pen? That was the cl...   \n",
       "4  ['According to the [review at Macstories](http...   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Goodnotes 4 vs. Goodnotes 5 right nowI have us...   \n",
       "1  The bundle is available !The bundle is availab...   \n",
       "2  Finally... GoodNotes 5! Did I miss anything in...   \n",
       "3  What happened to the pen (Goodnotes 5)?I just ...   \n",
       "4  Non Apple Pencil styluses on GOodnotes 5?I've ...   \n",
       "\n",
       "                                     reply_body_list  \n",
       "0  [I'm getting a ton of bugs with 5 as well (sna...  \n",
       "1  [Thank you. I have been waiting!\\n\\n&amp;#x200...  \n",
       "2  [Man i imagined you would be a lot more popula...  \n",
       "3  [Have you tried the ball pen? That was the clo...  \n",
       "4  [According to the [review at Macstories](https...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TotalCount:\",len(data))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting reply_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reply_body_list']=data['reply_body'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [I'm getting a ton of bugs with 5 as well (sna...\n",
       "1      [Thank you. I have been waiting!\\n\\n&amp;#x200...\n",
       "2      [Man i imagined you would be a lot more popula...\n",
       "3      [Have you tried the ball pen? That was the clo...\n",
       "4      [According to the [review at Macstories](https...\n",
       "                             ...                        \n",
       "674    [&gt;if she is dishonest about being a virgin ...\n",
       "675    [I updated to beta 2 yesterday and have been u...\n",
       "676    [Sex, Upvoted you. Please upvote me back, Ive ...\n",
       "677    [Something I also wish to know. I usually put ...\n",
       "678    [Iâ€™m intrigued., I've kinda given up on buying...\n",
       "Name: reply_body_list, Length: 679, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reply_body_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['submission_selftext'] = data['submission_selftext'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combining text in all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstNComments(commentList, n=3):\n",
    "    m = len(commentList)\n",
    "    if m==0:\n",
    "        return \"\"\n",
    "    \n",
    "    return \" \".join(commentList[:min(n,m)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['all_text'] = data.apply(lambda x: \" \".join([ \\\n",
    "     x['submission_title'], \\\n",
    "     x['submission_selftext'], \\\n",
    "     firstNComments(x['reply_body_list'], n=4) \\\n",
    "    ] ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Goodnotes 4 vs. Goodnotes 5 right now I have used Goodnotes 4 for work a ton.  And I do mean a ton.  I bought and downloaded 5 yesterday, transfer was easy.  I realized I can't use the Mac App with 5.  Right?  Changes I made in 5 aren't synced to the desktop app.  Also I kept getting a syncing error in 5.  What was it syncing with?  I am going to continue to play with it but I am not sure I feel comfortable diving in yet. I'm getting a ton of bugs with 5 as well (snappy lines, no response at times) and for some reason the ability to sync to google drive and to download multiple files at once from google drive is gone.\\n\\n I think they need some time to cope with the new launch. Goodnotes 5 is not yet compatible with the desktop app as it says in the release notes. There will be more features added in the near future.  I haven't downloaded GN5 yet but watched a walkthrough and I did see that there's a snap option to check and uncheck, I think somewhere in pen options. Hope that helps! That sounds a lot like what's going on, thanks!\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['all_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finally... GoodNotes 5! Did I miss anything in this video? Tried to point out all the \"new\" features.  Man i imagined you would be a lot more popular in this sub. Love your channel :)  Thank you :)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['all_text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split into labeled and unlabeled dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_df = data[data['submission_link_flair_text'].notna()]\n",
    "unlabelled_df = data[data['submission_link_flair_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled size: 241\n",
      "Unlabeled size: 438\n"
     ]
    }
   ],
   "source": [
    "print(\"Labeled size:\",len(labelled_df))\n",
    "print(\"Unlabeled size:\",len(unlabelled_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combining all Question tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Review', 'Question - iPad', 'Question - Other', 'Question - Mac',\n",
       "       'Stylus problems', 'Templates', 'Question - iPhone'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df['submission_link_flair_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/hvb1q6g96_qgcywwm07fmxhc0000gn/T/ipykernel_15518/638591540.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labelled_df['submission_link_flair_text'] = labelled_df['submission_link_flair_text'].apply(lambda x: \"Question\" if \"Question\" in x else x)\n"
     ]
    }
   ],
   "source": [
    "labelled_df['submission_link_flair_text'] = labelled_df['submission_link_flair_text'].apply(lambda x: \"Question\" if \"Question\" in x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Review', 'Question', 'Stylus problems', 'Templates'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df['submission_link_flair_text'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split the dataset into Training and TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tag_df = labelled_df[['all_text','submission_link_flair_text']] \\\n",
    "    .rename(columns={\"all_text\":\"input_text\",\"submission_link_flair_text\":\"target_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df,val_tag_df=train_test_split(all_tag_df, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size 192\n",
      "Validation size 49\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size\",len(train_tag_df))\n",
    "print(\"Validation size\",len(val_tag_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exporting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df.to_csv('singletask_noupsampling_train.csv',index=False)\n",
    "val_tag_df.to_csv('singlatask_noupsampling_val.csv',index=False)\n",
    "unlabelled_df.to_csv('unlabelled_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stylus problems</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Templates</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_text  input_text\n",
       "0         Question         141\n",
       "1           Review          15\n",
       "2  Stylus problems           3\n",
       "3        Templates          33"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_df.groupby(by='target_text').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_size = sum(train_tag_df['target_text']=='Review')\n",
    "stylus_size = sum(train_tag_df['target_text']=='Stylus problems')\n",
    "template_size = sum(train_tag_df['target_text']=='Templates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sampling desired number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12321\n",
    "\n",
    "upsampled_reviews = train_tag_df[train_tag_df['target_text']=='Review'] \\\n",
    "    .sample(review_size*3,replace=True, random_state=random_state)\n",
    "\n",
    "upsampled_problems = train_tag_df[train_tag_df['target_text']=='Stylus problems'] \\\n",
    "    .sample(stylus_size*3,replace=True, random_state=random_state)\n",
    "\n",
    "upsampled_templates = train_tag_df[train_tag_df['target_text']=='Templates'] \\\n",
    "    .sample(template_size*2,replace=True, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinating upsampled data with original train_tag_df, and reshuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df_extended = pd.concat([train_tag_df,upsampled_reviews,upsampled_problems, upsampled_templates]) \\\n",
    "    .sample(frac=1, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying upsampled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stylus problems</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Templates</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_text  input_text\n",
       "0         Question         141\n",
       "1           Review          60\n",
       "2  Stylus problems          12\n",
       "3        Templates          99"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_df_extended.groupby(by='target_text').count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exporing the expanded df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df_extended.to_csv('singletask_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manningLp",
   "language": "python",
   "name": "manninglp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
