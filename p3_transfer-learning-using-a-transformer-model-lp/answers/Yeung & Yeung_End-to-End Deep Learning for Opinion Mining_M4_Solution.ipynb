{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 4: Upload and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Upload model to transformer datahub\n",
    "- create an account\n",
    "- create a model repo \n",
    "- need to delete `tokenizer_config.json` before git commit to be used by T5Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 't5-reddit' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt-get install git-lfs \n",
    "git lfs install\n",
    "git clone https://vionwinnie:transformer123!@huggingface.co/vionwinnie/t5-reddit\n",
    "git config --global user.email \"dcvionwinnie@gmail.com\"\n",
    "git config --global user.name \"Man Wai Winnie Yeung\" \n",
    "\n",
    "# copy files over from model directory `cp ./multitask/* ./t5-reddit/`\n",
    "git status\n",
    "git add .\n",
    "git commit -m \"first push\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Call the uploaded data using HuggingFace syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.t5 import T5Config, T5ForConditionalGeneration, T5Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab798509e494591a3012fbaf77bf32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"vionwinnie/t5-reddit\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"vionwinnie/t5-reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Score using `model.generate()` and append the predictied tag to `unlabelled_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_selftext</th>\n",
       "      <th>submission_link_flair_text</th>\n",
       "      <th>reply_body</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aglcrj</td>\n",
       "      <td>Goodnotes 4 vs. Goodnotes 5 right now</td>\n",
       "      <td>I have used Goodnotes 4 for work a ton.  And I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"I'm getting a ton of bugs with 5 as well (sn...</td>\n",
       "      <td>Goodnotes 4 vs. Goodnotes 5 right nowI have us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agoowm</td>\n",
       "      <td>The bundle is available !</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Thank you. I have been waiting!\\n\\n&amp;amp;#x20...</td>\n",
       "      <td>The bundle is available !Thank you. I have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agpzxb</td>\n",
       "      <td>What happened to the pen (Goodnotes 5)?</td>\n",
       "      <td>I just got Goodnotes 5 and I was so excited fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Have you tried the ball pen? That was the cl...</td>\n",
       "      <td>What happened to the pen (Goodnotes 5)?I just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agqksi</td>\n",
       "      <td>Text/typing in Goodnotes 5</td>\n",
       "      <td>Notability user here, but trying out Goodnotes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"That's neat af\", 'Seattle, hopefully not too...</td>\n",
       "      <td>Text/typing in Goodnotes 5Notability user here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aiffh4</td>\n",
       "      <td>Using GoodNotes with Apple Files &amp;amp; Google ...</td>\n",
       "      <td>Is it possible for me to have a PDF stored in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['I don’t think so. I use pdf expert for doing...</td>\n",
       "      <td>Using GoodNotes with Apple Files &amp;amp; Google ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission_id                                   submission_title  \\\n",
       "0        aglcrj              Goodnotes 4 vs. Goodnotes 5 right now   \n",
       "1        agoowm                          The bundle is available !   \n",
       "2        agpzxb            What happened to the pen (Goodnotes 5)?   \n",
       "3        agqksi                         Text/typing in Goodnotes 5   \n",
       "4        aiffh4  Using GoodNotes with Apple Files &amp; Google ...   \n",
       "\n",
       "                                 submission_selftext  \\\n",
       "0  I have used Goodnotes 4 for work a ton.  And I...   \n",
       "1                                                NaN   \n",
       "2  I just got Goodnotes 5 and I was so excited fo...   \n",
       "3  Notability user here, but trying out Goodnotes...   \n",
       "4  Is it possible for me to have a PDF stored in ...   \n",
       "\n",
       "   submission_link_flair_text  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "\n",
       "                                          reply_body  \\\n",
       "0  [\"I'm getting a ton of bugs with 5 as well (sn...   \n",
       "1  ['Thank you. I have been waiting!\\n\\n&amp;#x20...   \n",
       "2  [\"Have you tried the ball pen? That was the cl...   \n",
       "3  [\"That's neat af\", 'Seattle, hopefully not too...   \n",
       "4  ['I don’t think so. I use pdf expert for doing...   \n",
       "\n",
       "                                            all_text  \n",
       "0  Goodnotes 4 vs. Goodnotes 5 right nowI have us...  \n",
       "1  The bundle is available !Thank you. I have bee...  \n",
       "2  What happened to the pen (Goodnotes 5)?I just ...  \n",
       "3  Text/typing in Goodnotes 5Notability user here...  \n",
       "4  Using GoodNotes with Apple Files &amp; Google ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('unlabelled_df.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strings = ('tag classification: '+test_df['all_text']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = tokenizer(all_strings,\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt',\n",
    "                        max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0th data\n",
      "processing 4th data\n",
      "processing 8th data\n",
      "processing 12th data\n",
      "processing 16th data\n",
      "processing 20th data\n",
      "processing 24th data\n",
      "processing 28th data\n",
      "processing 32th data\n",
      "processing 36th data\n",
      "processing 40th data\n",
      "processing 44th data\n",
      "processing 48th data\n",
      "processing 52th data\n",
      "processing 56th data\n",
      "processing 60th data\n",
      "processing 64th data\n",
      "processing 68th data\n",
      "processing 72th data\n",
      "processing 76th data\n",
      "processing 80th data\n",
      "processing 84th data\n",
      "processing 88th data\n",
      "processing 92th data\n",
      "processing 96th data\n",
      "processing 100th data\n",
      "processing 104th data\n",
      "processing 108th data\n",
      "processing 112th data\n",
      "processing 116th data\n",
      "processing 120th data\n",
      "processing 124th data\n",
      "processing 128th data\n",
      "processing 132th data\n",
      "processing 136th data\n",
      "processing 140th data\n",
      "processing 144th data\n",
      "processing 148th data\n",
      "processing 152th data\n",
      "processing 156th data\n",
      "processing 160th data\n",
      "processing 164th data\n",
      "processing 168th data\n",
      "processing 172th data\n",
      "processing 176th data\n",
      "processing 180th data\n",
      "processing 184th data\n",
      "processing 188th data\n",
      "processing 192th data\n",
      "processing 196th data\n",
      "processing 200th data\n",
      "processing 204th data\n",
      "processing 208th data\n",
      "processing 212th data\n",
      "processing 216th data\n",
      "processing 220th data\n",
      "processing 224th data\n",
      "processing 228th data\n",
      "processing 232th data\n",
      "processing 236th data\n",
      "processing 240th data\n",
      "processing 244th data\n",
      "processing 248th data\n",
      "processing 252th data\n",
      "processing 256th data\n",
      "processing 260th data\n",
      "processing 264th data\n",
      "processing 268th data\n",
      "processing 272th data\n",
      "processing 276th data\n",
      "processing 280th data\n",
      "processing 284th data\n",
      "processing 288th data\n",
      "processing 292th data\n",
      "processing 296th data\n",
      "processing 300th data\n",
      "processing 304th data\n",
      "processing 308th data\n",
      "processing 312th data\n",
      "processing 316th data\n",
      "processing 320th data\n",
      "processing 324th data\n",
      "processing 328th data\n",
      "processing 332th data\n",
      "processing 336th data\n",
      "processing 340th data\n",
      "processing 344th data\n",
      "processing 348th data\n",
      "processing 352th data\n",
      "processing 356th data\n",
      "processing 360th data\n",
      "processing 364th data\n",
      "processing 368th data\n",
      "processing 372th data\n",
      "processing 376th data\n",
      "processing 380th data\n",
      "processing 384th data\n",
      "processing 388th data\n",
      "processing 392th data\n",
      "processing 396th data\n",
      "processing 400th data\n",
      "processing 404th data\n",
      "processing 408th data\n",
      "processing 412th data\n",
      "processing 416th data\n",
      "processing 420th data\n",
      "processing 424th data\n",
      "processing 428th data\n",
      "['Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Templates', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Templates', 'Templates', 'Question', 'Templates', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Templates', 'Templates', 'Templates', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Templates', 'Templates', 'Templates', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Templates', 'Question', 'Templates', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Review', 'Question', 'Question', 'Templates', 'Question', 'Templates', 'Question', 'Review', 'Question', 'Review', 'Question', 'Templates', 'Templates', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Review', 'Review', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Review', 'Question', 'Question', 'Templates', 'Question', 'Templates', 'Question', 'Review', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Templates', 'Review', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Review', 'Question', 'Question', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Templates', 'Templates', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question', 'Question']\n"
     ]
    }
   ],
   "source": [
    "input_ids = input_batch[\"input_ids\"]\n",
    "attention_mask = input_batch[\"attention_mask\"]\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "batch_size = 4\n",
    "for i in range(0, len(all_strings), batchsize):\n",
    "    print(\"processing {}th data\".format(i))\n",
    "    subset_input_ids = input_ids[i:i+4]\n",
    "    subset_attention_masks = attention_mask[i:i+4]\n",
    "    if subset_input_ids.size()[0] >0:\n",
    "        prediction = model.generate(input_ids=subset_input_ids,\n",
    "                        attention_mask=subset_attention_masks,\n",
    "                        num_beams=4,\n",
    "                        max_length=300,\n",
    "                        do_sample=True,\n",
    "                        top_k=50,\n",
    "                        top_p=0.95,\n",
    "                        num_return_sequences=1)\n",
    "        for pred in prediction:\n",
    "            theme=tokenizer.decode(pred).replace('<pad>','').replace('</s>','').strip()\n",
    "            all_preds.append(theme)\n",
    "\n",
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_tag'] = all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('unlabelled_df_predicted.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. manually label some threads with tags and compare it with the inferred tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
