{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from simpletransformers.t5 import T5Model\n",
    "import yaml\n",
    "import ast\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Credentials\n",
    "with open(\"credentials.yaml\", 'r') as stream:\n",
    "    credentials = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_API_KEY=4d65a39548ffa3dc3f80181e7d16107fafcfa535\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_API_KEY=4d65a39548ffa3dc3f80181e7d16107fafcfa535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandbApiKey = credentials['wandb']['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('competitors_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1974, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for Title Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reply_body_list']=data['reply_body'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['submission_selftext'] = data['submission_selftext'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_link_flair_text</th>\n",
       "      <th>submission_selftext</th>\n",
       "      <th>reply_body</th>\n",
       "      <th>reply_body_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f96vya</td>\n",
       "      <td>New versions of A5 and A6 Agile firmwares are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "      <td>[\"There was video of a multifunction button to...</td>\n",
       "      <td>[There was video of a multifunction button to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>f9dsst</td>\n",
       "      <td>Feature request. Pressure sensitivity.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "      <td>['We are happy that you can enjoy this firmwar...</td>\n",
       "      <td>[We are happy that you can enjoy this firmware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fp66n4</td>\n",
       "      <td>Quick Guide — Set Up and Connect to the Supern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "      <td>[\"What I would like to know is where can one b...</td>\n",
       "      <td>[What I would like to know is where can one bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fs454n</td>\n",
       "      <td>How to use handwriting to text function?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "      <td>['Currently you can try the \"Smart Writing\" fu...</td>\n",
       "      <td>[Currently you can try the \"Smart Writing\" fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fs46fj</td>\n",
       "      <td>Email inbox issues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "      <td>[\"Hi aubrit512,\\n\\nPlease try to update the sy...</td>\n",
       "      <td>[Hi aubrit512,\\n\\nPlease try to update the sys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index submission_id                                   submission_title  \\\n",
       "0      0        f96vya  New versions of A5 and A6 Agile firmwares are ...   \n",
       "1      1        f9dsst             Feature request. Pressure sensitivity.   \n",
       "2      2        fp66n4  Quick Guide — Set Up and Connect to the Supern...   \n",
       "3      3        fs454n           How to use handwriting to text function?   \n",
       "4      4        fs46fj                                 Email inbox issues   \n",
       "\n",
       "  submission_link_flair_text  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "\n",
       "                                 submission_selftext  \\\n",
       "0  Dear Supernote users, new versions of A5 and A...   \n",
       "1  Thank you for the new firmware update. It adds...   \n",
       "2  Set up and connect to the Supernote Cloud acco...   \n",
       "3  How do you achieve this? I've not been able to...   \n",
       "4  I have set up my email, and can send emails. M...   \n",
       "\n",
       "                                          reply_body  \\\n",
       "0  [\"There was video of a multifunction button to...   \n",
       "1  ['We are happy that you can enjoy this firmwar...   \n",
       "2  [\"What I would like to know is where can one b...   \n",
       "3  ['Currently you can try the \"Smart Writing\" fu...   \n",
       "4  [\"Hi aubrit512,\\n\\nPlease try to update the sy...   \n",
       "\n",
       "                                     reply_body_list  \n",
       "0  [There was video of a multifunction button to ...  \n",
       "1  [We are happy that you can enjoy this firmware...  \n",
       "2  [What I would like to know is where can one bu...  \n",
       "3  [Currently you can try the \"Smart Writing\" fun...  \n",
       "4  [Hi aubrit512,\\n\\nPlease try to update the sys...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstNComments(commentList, n=3):\n",
    "    m = len(commentList)\n",
    "    if m==0:\n",
    "        return \"\"\n",
    "    \n",
    "    return \" \".join(commentList[:min(n,m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['all_text'] = data.apply(lambda x: \" \".join([ \\\n",
    "     x['submission_selftext'], \\\n",
    "     firstNComments(x['reply_body_list'], n=4) \\\n",
    "    ] ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data: 1974\n",
      "Data with title not nan: 1974\n",
      "Data with title > 0 characters long 1974\n",
      "So no need to remove data with no title\n"
     ]
    }
   ],
   "source": [
    "print(\"All data:\", len(data))\n",
    "print(\"Data with title not nan:\",sum(data['submission_title'].notna()))\n",
    "print(\"Data with title > 0 characters long\",sum(data['submission_title'].apply(lambda x: len(x.strip()))>0))\n",
    "\n",
    "print(\"So no need to remove data with no title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_link_flair_text</th>\n",
       "      <th>submission_selftext</th>\n",
       "      <th>reply_body</th>\n",
       "      <th>reply_body_list</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f96vya</td>\n",
       "      <td>New versions of A5 and A6 Agile firmwares are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "      <td>[\"There was video of a multifunction button to...</td>\n",
       "      <td>[There was video of a multifunction button to ...</td>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>f9dsst</td>\n",
       "      <td>Feature request. Pressure sensitivity.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "      <td>['We are happy that you can enjoy this firmwar...</td>\n",
       "      <td>[We are happy that you can enjoy this firmware...</td>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fp66n4</td>\n",
       "      <td>Quick Guide — Set Up and Connect to the Supern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "      <td>[\"What I would like to know is where can one b...</td>\n",
       "      <td>[What I would like to know is where can one bu...</td>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fs454n</td>\n",
       "      <td>How to use handwriting to text function?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "      <td>['Currently you can try the \"Smart Writing\" fu...</td>\n",
       "      <td>[Currently you can try the \"Smart Writing\" fun...</td>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fs46fj</td>\n",
       "      <td>Email inbox issues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "      <td>[\"Hi aubrit512,\\n\\nPlease try to update the sy...</td>\n",
       "      <td>[Hi aubrit512,\\n\\nPlease try to update the sys...</td>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index submission_id                                   submission_title  \\\n",
       "0      0        f96vya  New versions of A5 and A6 Agile firmwares are ...   \n",
       "1      1        f9dsst             Feature request. Pressure sensitivity.   \n",
       "2      2        fp66n4  Quick Guide — Set Up and Connect to the Supern...   \n",
       "3      3        fs454n           How to use handwriting to text function?   \n",
       "4      4        fs46fj                                 Email inbox issues   \n",
       "\n",
       "  submission_link_flair_text  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "\n",
       "                                 submission_selftext  \\\n",
       "0  Dear Supernote users, new versions of A5 and A...   \n",
       "1  Thank you for the new firmware update. It adds...   \n",
       "2  Set up and connect to the Supernote Cloud acco...   \n",
       "3  How do you achieve this? I've not been able to...   \n",
       "4  I have set up my email, and can send emails. M...   \n",
       "\n",
       "                                          reply_body  \\\n",
       "0  [\"There was video of a multifunction button to...   \n",
       "1  ['We are happy that you can enjoy this firmwar...   \n",
       "2  [\"What I would like to know is where can one b...   \n",
       "3  ['Currently you can try the \"Smart Writing\" fu...   \n",
       "4  [\"Hi aubrit512,\\n\\nPlease try to update the sy...   \n",
       "\n",
       "                                     reply_body_list  \\\n",
       "0  [There was video of a multifunction button to ...   \n",
       "1  [We are happy that you can enjoy this firmware...   \n",
       "2  [What I would like to know is where can one bu...   \n",
       "3  [Currently you can try the \"Smart Writing\" fun...   \n",
       "4  [Hi aubrit512,\\n\\nPlease try to update the sys...   \n",
       "\n",
       "                                            all_text  \n",
       "0  Dear Supernote users, new versions of A5 and A...  \n",
       "1  Thank you for the new firmware update. It adds...  \n",
       "2  Set up and connect to the Supernote Cloud acco...  \n",
       "3  How do you achieve this? I've not been able to...  \n",
       "4  I have set up my email, and can send emails. M...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_df = data[['all_text','submission_title']] \\\n",
    "    .rename(columns={\"all_text\":\"input_text\",\"submission_title\":\"target_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_df['prefix']='title prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "      <td>New versions of A5 and A6 Agile firmwares are ...</td>\n",
       "      <td>title prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "      <td>Feature request. Pressure sensitivity.</td>\n",
       "      <td>title prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "      <td>Quick Guide — Set Up and Connect to the Supern...</td>\n",
       "      <td>title prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "      <td>How to use handwriting to text function?</td>\n",
       "      <td>title prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "      <td>Email inbox issues</td>\n",
       "      <td>title prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  Dear Supernote users, new versions of A5 and A...   \n",
       "1  Thank you for the new firmware update. It adds...   \n",
       "2  Set up and connect to the Supernote Cloud acco...   \n",
       "3  How do you achieve this? I've not been able to...   \n",
       "4  I have set up my email, and can send emails. M...   \n",
       "\n",
       "                                         target_text            prefix  \n",
       "0  New versions of A5 and A6 Agile firmwares are ...  title prediction  \n",
       "1             Feature request. Pressure sensitivity.  title prediction  \n",
       "2  Quick Guide — Set Up and Connect to the Supern...  title prediction  \n",
       "3           How to use handwriting to text function?  title prediction  \n",
       "4                                 Email inbox issues  title prediction  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_titles_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_df.to_csv('all_titles_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_df,val_title_df=train_test_split(all_titles_df, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 1776\n",
      "test size: 198\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\",len(train_title_df))\n",
    "print(\"test size:\",len(val_title_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df = pd.read_csv('singletask_train.csv')\n",
    "val_tag_df = pd.read_csv('singlatask_noupsampling_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df['prefix']=''\n",
    "val_tag_df['prefix']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Battery drain i’ve been using my ipadpro for n...</td>\n",
       "      <td>Question</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GoodNotes on iCloud I can not find my GoodNote...</td>\n",
       "      <td>Question</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flash card shuffle? Is there a way to shuffle ...</td>\n",
       "      <td>Question</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First Attempt With GoodNotes! Any thought?  Ni...</td>\n",
       "      <td>Review</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which backup is the best for good notes - Drop...</td>\n",
       "      <td>Question</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text target_text prefix\n",
       "0  Battery drain i’ve been using my ipadpro for n...    Question       \n",
       "1  GoodNotes on iCloud I can not find my GoodNote...    Question       \n",
       "2  Flash card shuffle? Is there a way to shuffle ...    Question       \n",
       "3  First Attempt With GoodNotes! Any thought?  Ni...      Review       \n",
       "4  Which backup is the best for good notes - Drop...    Question       "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_df = pd.concat([train_title_df,train_tag_df])\n",
    "val_combined_df = pd.concat([val_title_df,val_tag_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2088, 3)\n",
      "test: (247, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\",train_combined_df.shape)\n",
    "print(\"test:\",val_combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"output_dir\": './single-task-noupsample', #specify output directory\n",
    "    \"max_seq_length\": 400,\n",
    "    \"train_batch_size\": 2,\n",
    "    \"eval_batch_size\": 2,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"evaluate_during_training_steps\": 15000,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    \"use_multiprocessing\": False,\n",
    "    \"fp16\": False,\n",
    "    \"save_steps\": -1,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"wandb_project\": \"T5 - multi task\",\n",
    "    \"use_cuda\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f6fc8edd4f492cb67f170179c108d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3402: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adafactor for T5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2b5dbccd884791bfd3346fc7475f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:l3qayxkb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 51026... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">jolly-frost-1</strong>: <a href=\"https://wandb.ai/roivian/T5%20-%20single%20task/runs/l3qayxkb\" target=\"_blank\">https://wandb.ai/roivian/T5%20-%20single%20task/runs/l3qayxkb</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211022_173449-l3qayxkb/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:l3qayxkb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/roivian/T5%20-%20multi%20task/runs/3ivxs7ob\" target=\"_blank\">hopeful-sound-1</a></strong> to <a href=\"https://wandb.ai/roivian/T5%20-%20multi%20task\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b3a0c0588a44e3ac981548a022b498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/1044 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1219dfdfc0c748b089e56d75f10e5caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5177289095f4b31babd34897218cd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/1044 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe17b2089f647d98fb37af91bd29ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3402: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09c471fcd174178934cdb508b9243d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/1044 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdde9d4ac7746e6aa68ac78b795a3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3402: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3132,\n",
       " {'global_step': [1044, 2088, 3132],\n",
       "  'eval_loss': [0.5957901629416512, 0.1593266632140923, 0.07726606870035597],\n",
       "  'train_loss': [1.01181960105896, 0.02049863524734974, 0.49937084317207336]})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5Model(\"t5\", \"t5-small\", args=model_args, use_cuda=False)\n",
    "model.train_model(train_combined_df, eval_data=val_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = val_tag_df[\"target_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f005b37c214649a5b0dc12193896d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3402: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e1f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e8b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39e9d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39eaf0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39ec10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39ed30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39ee50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b39ef70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3930d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3931f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3938b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3939d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b393f70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3850d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3851f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3858b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b282a60> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b282b80> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b3859d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b385f70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d70d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d71f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d78b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d79d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2d7e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c40d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c41f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c48b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c49d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2c4f70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e30d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e31f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e38b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e39d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2e3f70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a50d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a51f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a58b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a59d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2a5f70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b70d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633fade77d1a454ba0af1402cbd4e475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b71f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b78b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b79d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7af0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7c10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7d30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7e50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2b7f70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca0d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca1f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca790> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca8b0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ca9d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2caaf0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2cac10> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2cad30> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2cae50> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2caf70> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ba0d0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ba1f0> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ba310> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ba430> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ba550> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/torch/utils/hooks.py:59: UserWarning: backward hook <function TorchHistory._hook_variable_gradient_stats.<locals>.<lambda> at 0x14b2ba670> on tensor will not be serialized.  If this is expected, you can decorate the function with @torch.utils.hooks.unserializable_hook to suppress this warning\n",
      "  warnings.warn(\"backward hook {} on tensor will not be \"\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "to_predict = [\n",
    "    prefix + \": \" + str(input_text)\n",
    "    for prefix, input_text in zip(val_tag_df[\"prefix\"].tolist(), val_tag_df[\"input_text\"].tolist())\n",
    "]\n",
    "#y_true = val_tag_df[\"target_text\"].tolist()\n",
    "tasks = val_tag_df[\"prefix\"].tolist()\n",
    "\n",
    "# Get the model predictions\n",
    "y_pred = model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Question       0.92      0.92      0.92        39\n",
      "         Review       0.50      0.50      0.50         2\n",
      "Stylus problems       0.00      0.00      0.00         2\n",
      "      Templates       0.75      1.00      0.86         6\n",
      "\n",
      "       accuracy                           0.88        49\n",
      "      macro avg       0.54      0.61      0.57        49\n",
      "   weighted avg       0.85      0.88      0.86        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roman/test/code/manning/manning-lp/myvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_tag_df['target_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAI/CAYAAABd3iKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1SElEQVR4nO3deZwcdZn48c+TTEIgIIeEIUJWjiByqUhEPFY5RBA8EGEVFWEXjceiongg+EJEYfH+eSJBLl2PRURFLkEOOXRFwBACeKEYjpCAikA4cj2/P7qGbWIyXTOZ6u7q/rzzqtd0VVdXPT2V6X76+R4dmYkkSVI3GdfpACRJklZkgiJJkrqOCYokSeo6JiiSJKnrmKBIkqSuY4IiSZK6zkDVJ1hzx8Mdx1xjC3/5pU6HoFFavGx5p0PQapi8RuUvz6rQpAGinedr53vto7/5SluemxUUSZLUdUzRJUmqu+i9ekPvPSNJklR7VlAkSaq7aGuXl7awgiJJkrqOCYokSeo6NvFIklR3dpKVJEmqnhUUSZLqzk6ykiRJ1bOCIklS3XVJH5SImARcBaxBI8c4JzM/FhFnAi8F/lHsemhmzh7uWCYokiRprDwO7J6ZD0fEBOCaiLiouO+DmXlO2QOZoEiSVHdd0gclMxN4uFidUCyj+iLD7qgJSZKknhAR4yNiNrAQuDQzf1XcdUJEzImIL0TEGq2OY4IiSVLdxbi2LRExMyKub1pmNoeSmcsy8znApsDOEbE98BHgmcDzgA2AD7d6SjbxSJKk0jJzFjCrxH4PRMQVwN6Z+dli8+MRcQbwgVaPt4IiSVLdRbRvGTaMmBIR6xW31wT2BH4bEVOLbQHsB8xt9ZSsoEiSpLEyFTgrIsbTKIKcnZnnR8TlETEFCGA28I5WBzJBkSSp7rpkHpTMnAPsuJLtu4/0WN3xjCRJkppYQZEkqe66ZB6UsWQFRZIkdR0TFEmS1HVs4pEkqe66pJPsWOq9ZyRJkmrPCookSXVnJ1lJkqTqWUGRJKnu7IMiSZJUPSsokiTVnRUUSZKk6llBkSSp7sY5ikeSJKlyVlAkSao7+6BIkiRVzwqKJEl150yykiRJ1bOCIklS3dkHRZIkqXomKJIkqevYxCNJUt3ZSVaSJKl6VlAkSao7O8lKkiRVzwqKJEl114N9UEonKBGxB7Bl82My82tVBCVJkvpbqQQlIs4EZgA3AsuKzVlRTJIkaSR6sA9K2QrKC4HtMnNJlcFIkiRB+QTlzkqjkCRJo9fHfVB+D1wWET8CHhvaaB8USZJUhbIJyiTgdmCHpm32QZEkqRv0ax+UzPz3qgORJEkaUnYUTwAzgZcVmy4BvpGZVlEkSeq0Pu6D8mlgR+CMYv0QYCvgQ1UEJUmS+lvZBGUv4LmZuRQgIs4GbsAERZKkzuvBPihln1Hw5E6xWWyTJEkac2UrKD8FLipmlIVGE8/FlUQkSZL6XtkE5UPA24H9i/UfArMqiUiSJI1MDzbxlB1mvBw4uVgkSZIqNWyCEhHvzcwvRsRnWMnEbJlpJ1lJkjqtD4cZD01r/3DVgUiSJA0ZNkHJzFOKm/+Tmb9tvi8inllZVJIkqbx+7YMCfAd4boltPWuNiQP87LQjmDhxgIHx4/nhz37DJ79+IQDH/eer2H/PHVm2bDmnnnM1X/vuzzscrVr5+LHHcM1VV7L+Bhtw9rk/6XQ4GoEF987nE8d+hL/99a9EBK/e/0Be/8aDOx2WSrr26qv41EknsHzZcl77ugM57G0zOx2SulSrPigbAhsBkyJiG/5v7pN1gckVx9ZVHl+8lL1nfolFjy5mYGAcl5/+fi659la23nxjNt14PZ792k+QmUxZf+1Oh6oSXvWa/Xj9QW/k2GOO6nQoGqHx4wd49/s+xNbbbMuiRYv4jzcdyM67vIDNt5je6dDUwrJlyzjxhOM55dQzGBwc5I2vP4Bdd9udLad77VZbH/ZBeRNwBPA04MKm7f+gMf19X1n06GIAJgyMZ2BgPJnJzANfzCFHn8nQ1xLd93e769TBc3d6HvfcfXenw9AobDhlChtOmQLA5MmTefrmW3DfwoUmKDUw9+Y5TJv2dDadNg2AvffZlyuvuMwERSvVqg/KF4EvRsTRmXlim2LqWuPGBb/4zofZctoUTvmfq/j13L+w+aZTOODlO/Hq3Z/N/X9/iCM/fQ63z7uv06FKfWH+PXfzh9/dxnbbP6vToaiEhQsWsPHUjZ9Y32hwkJvnzOlgRD2kB/uglH1G50TEJICI2CsijoqI9SuMqystX57s8oaTmL7XR5mx/dPZdsuprDFxgMcXL+HFb/o0Z5z7C0752Js6HabUFx55ZBFHf+AI3nvkUUxe26ZVqdeUTVDOBpZFxObAKcAWwFmr2jkiZkbE9RFx/dL7bxmDMLvLPx5+lJ9f/3te/sJtuXvB3/nRZTcB8OPLb2L7rTbpcHRS71u6ZAlHf+AIXr7Pvuy6x56dDkclbTQ4yL3z731ifeGCBQwODnYwoh4S0b6lTcomKMszcwmwL/C1zJwJ/Muqds7MWZk5IzNnDGy43VjE2XEbrr826669JgCT1pjAHs9/Jr+7YwE/uXIOL33eVgD8605b8cd5CzsZptTzMpMTjz+WzTbfgoPefGinw9EIbLf9Dsybdwd33XUnSxYv5uILL+Clu+3e6bDUpcoOM54UEYPAq4Bjim2912V4GBtv+BROPf5gxo8bx7hxwQ8uvZGLrp7LL35zO2eceAjvftPuLHr0cd55/Hc6HapKOPrDR3LD9dfxwAMPsM+euzLznYez3/4HdDoslTBn9o1cfMF5bDn9GRzyhsbXg7398CN44Ytf0uHI1MrAwAAfOeZY3jnzrSxfvoz9Xvs6pk/fqtNh9YTowVE8MTT6ZNidImbSGLVzWWa+LiK2AM7MzJavCGvueHjrE6hrLfzllzodgkZp8bLlnQ5Bq2HyGmU/P6obTRpo74f4tV53etveax/5wX+05bmV/bLAWTz524v/AryskogkSdKI9GIFpVQflIhYKyI+ERHfLjZtBexTXViSJKmfle0kezIwAXhOsX4X8LEqApIkSSqboDwrM48CFgNk5sMjeKwkSapStHFpk7JJxuPNK8WkbSYokiSpEmW7iV8VEUcDa0TErsD7gR9XFZQkSSqvbzvJ0pj7JICHaAw3vg44rqKYJElSnys7zHgJcEKxSJKkLtKLFZRSCUpEfHpl2zPzQ2MbjiRJUvk+KIuabk8CXglcP/bhSJKkkerbCkpmfrx5PSJOBM6pJCJJktT3RvtlDw8zzLcZS5Kk9unbCkpEfAYY+iKiccBOwG1VBSVJkvpb2QrKw/xfgrIU+DpwbiURSZKkkem9AkrrBCUidgN2B3agkaRcC5yfmUsiYmJmLq44RkmS1GeGnagtIg4AvgV8l0aSsgdwEXB2RDwL+EnlEUqSpGFFRNuWFnFMiojrIuKmiLglIj5ebN88In4VEX+MiP+JiImtnlOrCsrRwF6ZeUvTttkRcTWN2WS/0+oEkiSpbzwO7J6ZD0fEBOCaiLiIxlfkfCEzvxcRXwcOA04e7kCtprqftEJyAkBmzgXuAd4+qvAlSdKY6ZYKSjY8XKxOKJak0QozND3JWcB+rZ5TqwRlYpEBrfiLWAOIzFzW6gSSJKl/RMT4iJgNLAQuBW4HHsjMpcUudwGbtDpOqwTlx8A3I2LdphOvB5yJ32YsSVLfiYiZEXF90zKz+f7MXJaZzwE2BXYGnjma87Tqg/IRGm1Ed0bEH4tt04HvF/dJkqQOa+dEbZk5C5hVYr8HIuIK4AXAehExUFRRNgXubvX4YROUYgjxYUUv3B1ojLS+OTP/UuI5SJKkPhIRU4AlRXKyJrAn8CngCuAA4HvAIZRohSn7XTzzgHmjjliSJFWmi6a6nwqcFRHjaXQjOTszz4+IW4HvRcQngd8Ap7U60Gi/i0eSJOlJMnMOsONKtv+JRn+U0kxQJEmqu64poIydVqN4JEmS2s4KiiRJNddFfVDGjBUUSZLUdaygSJJUc1ZQJEmS2sAKiiRJNWcFRZIkqQ2soEiSVHe9V0CxgiJJkrqPFRRJkmrOPiiSJEltYAVFkqSas4IiSZLUBiYokiSp69jEI0lSzdnEI0mS1AZWUCRJqjkrKJIkSW1gBUWSpLrrvQKKFRRJktR9rKBIklRz9kGRJElqAysokiTVnBUUSZKkNrCCIklSzVlBkSRJagMrKJIk1V3vFVCsoEiSpO5jBUWSpJqzD4okSVIbmKBIkqSuYxOPJEk1ZxOPJElSG1hBkSSp5qygSJIktYEVFEmSas4KiiRJUhtYQZEkqe56r4BiBUWSJHWfyisoC3/5papPIWklJq9hgVTqF/ZBkSRJagM/YkmSVHNWUCRJktrACookSTXXgwUUKyiSJKn7WEGRJKnm7IMiSZLUBiYokiSp69jEI0lSzfVgC48VFEmS1H2soEiSVHN2kpUkSWoDKyiSJNVcDxZQrKBIkqTuYwVFkqSaGzeu90ooVlAkSVLXsYIiSVLN2QdFkiSpDaygSJJUc86DIkmS1AZWUCRJqrkeLKBYQZEkSd3HCookSTVnHxRJkqQ2MEGRJEldxwRFkqSai4i2LS3imBYRV0TErRFxS0S8t9h+XETcHRGzi2WfVs/JPiiSJGmsLAWOzMwbI2Id4IaIuLS47wuZ+dmyBzJBkSSp5rqlj2xmzgfmF7cfiojbgE1GcyybeCRJ0piLiM2AHYFfFZsOj4g5EXF6RKzf6vEmKJIk1Vw7+6BExMyIuL5pmbmSeNYGfgAckZkPAicDWwLPoVFh+Vyr52QTjyRJKi0zZwGzVnV/REygkZx8OzPPLR6zoOn+U4HzW53HBEWSpJrrlj4o0RjmcxpwW2Z+vmn71KJ/CsBrgbmtjmWCIkmSxsqLgIOBmyNidrHtaOCgiHgOkMAdwNtbHcgERZKkmuuWqe4z8xpgZcFcONJj2UlWkiR1HSsokiTVXJcUUMaUFRRJktR1rKBIklRz3dIHZSxZQZEkSV3HCookSTXXgwUUKyiSJKn7mKBIkqSuYxOPJEk1ZydZSZKkNrCCIklSzfVgAcUKiiRJ6j5WUCRJqjn7oEiSJLWBFRRJkmquBwsoVlAkSVL3sYIiSVLN9W0flIi4MyLOiohDImLTqoOSJEn9rWwTz3OBi4B/Ba6KiN9FxNeqC0uSJJUV0b6lXUo18WTmfRHxfeBOYB5wKPCSCuOSJEl9rFSCEhHnA5sB1wGXAS/KzPkVxiVJkkrq2z4oxX5D+yawvJpwJEmSyjfx7BMRA8AuwO7AJyJiUWY+q9LoJElSS71YQSnbxLMhjcRkT2APYBnwiwrjkiRJfazsPCizgcuL5ROZOa+yiCRJUt8r28Tj3CeSJHWpHmzhKT1R20YR8d8RcVWx/qyIeEe1oUmSpH5VdhTPqcA1wHrF+m+Bd1URkCRJGpmIaNvSLmUTlE0y8+s0OseSmYvp86HGHz/2GPbc9UX82/6v6nQoGgWvX71de/VVvHrfvXjl3nty2qmzOh2ORsBrp7LKJihLm1ciYj2gB1u8ynvVa/bjyyf7x1VXXr/6WrZsGSeecDxf+/o3+OF5F3Dxhedz+x//2OmwVILXrjq9ONV92QTl3Ig4BVgnIg4FLgFOryyqGnjuTs/jKU9Zr9NhaJS8fvU19+Y5TJv2dDadNo0JEyey9z77cuUVl3U6LJXgtdNIlEpQMvPTwFXADcA+wJcy84tVBiZJK7NwwQI2nrrxE+sbDQ6yYMGCDkaksrx21enFPihl50EhM78NfLvCWCRJkoAWCUpEvDczvxgRn6HxHTxPkpkfWsXjZgIzAb74lZP598NmjkWsksRGg4PcO//eJ9YXLljA4OBgByNSWV676vTjPCiPFT8fBhatZFmpzJyVmTMyc4bJiaSxtN32OzBv3h3cddedLFm8mIsvvICX7rZ7p8NSCV47jcSwFZTMPKW4+enMfLQN8dTG0R8+khuuv44HHniAffbclZnvPJz99j+g02GpJK9ffQ0MDPCRY47lnTPfyvLly9jvta9j+vStOh2WSvDaVWdcD5ZQIvOfWm7+eaeI+4AfA2dk5rUjOcFDjy1vfQJJY27CQNlBepLG2qSB9k7FsedX/rdt77WXHr5LW55b2VewrWl8YeAXI+L3EXF0RPj9PJIkdYG+nQclM/+WmV/JzBnA/sBWwJ8rjUySJPWt0sOMI2IcjTlQDgVeApxZTUiSJGkk2jk/SbuUSlAi4vPAG4C5wFnAwXaalSRJVSlbQfkr8PzMvLPKYCRJkqB8H5QTgDUj4jUAEbFORGxQaWSSJKmUcdG+pW3PqcxOEXEIcB7whWLT04CzqwpKkiT1t7JNPEcAM4CrATLzdxGx8bCPkCRJbdGLnWTLzoOyODMfXmHb0rEORpIkCUbQSTYinkHxhYER8WbgrsqikiRJpfVgAWVETTzfAbaOiDuAR4C3VRSTJEnqcy0TlKKvyTrALjRmkJ0CHAicD6xfaXSSJKmlaO9X/7TFsH1QIuIw4C/ABcBvaHwnz3nARjQ6zUqSJI25VhWU9wPPzcxbIuJFwJXAQZl5TuWRSZKkUto5P0m7tBrFsyQzbwHIzGuB201OJElS1VpVUCZGxDbwROPW8ub1zLy1yuAkSVJrvTgPSqsEZS3gwhW2Da0nsMWYRyRJkvresAlKZm7WpjgkSdIo9WABpfRMspIkSW1TdqI2SZLUpcb1YAnFCookSeo6JiiSJKnr2MQjSVLN9WALjxUUSZLUfaygSJJUc704UZsVFEmS1HWsoEiSVHM9WECxgiJJkrqPFRRJkmrOidokSZLawARFkqSaizYuw8YRMS0iroiIWyPiloh4b7F9g4i4NCL+UPxcv9VzMkGRJEljZSlwZGZuC+wC/GdEbAscBVyWmVsBlxXrw7IPiiRJNdct86Bk5nxgfnH7oYi4DdgEeA2wa7HbWcCVwIeHO5YVFEmSNOYiYjNgR+BXwGCRvADcCwy2erwVFEmSam5cGwsoETETmNm0aVZmzlphn7WBHwBHZOaDzRWezMyIyFbnMUGRJEmlFcnIrFXdHxETaCQn387Mc4vNCyJiambOj4ipwMJW57GJR5KkmouIti0t4gjgNOC2zPx8013nAYcUtw8BftzqOVlBkSRJY+VFwMHAzRExu9h2NHAScHZEHAb8Bfi3VgcyQZEkSWMiM69h1dOl7DGSY5mgSJJUc10yynhM2QdFkiR1HSsokiTVXLdM1DaWrKBIkqSuYwVFkqSaa+dEbe1iBUWSJHUdKyiSJNWcfVAkSZLawAqKJEk113v1EysokiSpC1lBkSSp5sbZB0WSJKl6VlAkSaq5HiygWEGRJEndxwqKJEk15zwokiRJbWCCIkmSuo5NPJIk1VwPtvBYQZEkSd3HCookSTXnRG2SJEltYAVFkqSa68ECihUUSZLUfaygSJJUc07UJkmS1AaVV1AmDJgDSZ3w5/sWdToErYbNp0zudAiqkV58p+3F5yRJkmrOPiiSJNWcfVAkSZLawAqKJEk1N673CihWUCRJUvexgiJJUs1ZQZEkSWoDKyiSJNWco3gkSZLawARFkiR1HZt4JEmqOTvJSpIktYEVFEmSaq4H+8haQZEkSd3HCookSTU3rgdLKFZQJElS17GCIklSzfVitaEXn5MkSao5KyiSJNVcD3ZBsYIiSZK6jxUUSZJqzlE8kiRJbWAFRZKkmuvBAooVFEmS1H2soEiSVHN+m7EkSVIbmKBIkqSuYxOPJEk15zBjSZKkNrCCIklSzfVgAcUKiiRJ6j5WUCRJqjmHGUuSJLWBFRRJkmou6L0SihUUSZLUdaygSJJUc/ZBkSRJagMrKJIk1ZwVFEmSpDawgiJJUs1FD04lawVFkiSNmYg4PSIWRsTcpm3HRcTdETG7WPZpdZyWCUpEvD4inlLcPj4iLo6InVYvfEmSNFbGRfuWEs4E9l7J9i9k5nOK5cKWz6nEiT6amQ9GxM7AXsA3gS+XClGSJPWVzLwK+NvqHqdMgrKk+Lkn8I3M/A4waXVPLEmS+srhETGnaAJav9XOZRKUjIjXA28AflZsm7g6EUqSpLET0c4lZkbE9U3LzBIhngxsCTwHmA98rtUDyoziORz4MI3qyZ8jYivgihKPkyRJPSYzZwGzRviYBUO3I+JU4PxWj2mZoGTmL4H9mtb/ALx7JIFJkqTqjOvyYcYRMTUz5xerrwXmDrc/lBvFs1VEXBMRfy7WnxsRx61WpJIkqSdFxHeBXwJbR8RdEXEY8OmIuDki5gC7Ae9rdZwyTTwnA58ETirWZwPfAo4bRdySJGmMddNU95l50Eo2nzbS45TpJLtuZl4MZHHi5cDikZ5IkiSprDIVlGURMYEiQYmITYDllUYlSZJK6/IuKKNSpoLyNeCHwIZF35Orgc9WGZQkSepvZUbxfDMi/gS8ClgLOCQzr648MkmSVMo4eq+E0jJBiYg3Z+Z/A9esZJskSdKYK9PE8/6S2yRJUge0cybZdlllBSUiZgDPp9H35F1Nd62LU91LkqQKDdfEswkwA5gMPK9p+4PAoRXGJEmSRqCb5kEZK6tMUDLzx8CPI+LlmXlJG2OSJEl9rswonksiYmvg2cCkpu3frDIwSZJUTrd/F89olBnF8x7g7cBU4NfAvwI/B0xQJElSJcqM4pkJ7AzMy8y9itsPVRqVJEnqa2Wmun8sMxdFxLiIiMycGxHPqDwySZJUSg+28JSqoDxSfBfPTcCnIuLdwPhqw6qHa6++ilfvuxev3HtPTjt1VqfD0Qh47ert4Yce4lPHfpD/PHh/Dn/L/vz2lps6HZJK8m9PZZWpoLyLxrwnRwInAlsAB1cZVB0sW7aME084nlNOPYPBwUHe+PoD2HW33dly+vROh6YWvHb1d9pXPsNzd34hHz7+MyxZsoTHH3us0yGpBP/2qtOLnWRbVlAyc25mLsrMhZn51sw8IDNntyG2rjb35jlMm/Z0Np02jQkTJ7L3Pvty5RWXdTosleC1q7dFDz/ELTfdyMv23Q+ACRMmsPY663Q2KJXi355GYriZZD893AMz80NjH059LFywgI2nbvzE+kaDg9w8Z04HI1JZXrt6WzD/HtZdb32+dNJx3HH779nyGdvw1nd/kElrrtnp0NSCf3vV6cECyrAVlEUtFklqu+XLlnH773/LK15zAF/4xneZtOaa/OA7Z3Q6LEljbLiZZD8+2oNGxEwaw5P5ytdO4bC3zRztobrWRoOD3Dv/3ifWFy5YwODgYAcjUlleu3p76pSNeOqUjXjGtjsA8IKX7sG53zmzs0GpFP/2qlNmxEvdtHxOEbFORHw6Iq4vlk9FxLANvpk5KzNnZOaMXkxOALbbfgfmzbuDu+66kyWLF3PxhRfw0t1273RYKsFrV2/rP3VDNtxokLvn3QHAnBuuY9rTN+9sUCrFvz2NRJlRPKfT+ILA9xTr/w6cARxQVVB1MDAwwEeOOZZ3znwry5cvY7/Xvo7p07fqdFgqwWtXf297z4f5/CePYenSJQxO3ZT3HHVcp0NSCf7tVSd6sBNKZObwO0TclpnbtNq2Ko8tZfgTSKrEn++zq1idbT5lcqdD0GqYNEBbM4azrr+zbe+1h8yY1pbnVqaCck9EbJiZ9wNExFOBu6sNS5IkldV79ZNyCcr9wE0RcX6xvi9w9dAw5H4fbixJksZemQTl1mIZcmpFsUiSpFHoxZlkWyYoqzPcWJIkaTRaJigRsSZwEDC9eX+bdiRJ6g69Vz8p18RzLrAcuAF4vNpwJEmSyiUo/5KZ21UeiSRJUqFMgjI3IqZm5vzKo5EkSSPWg31kSyUoHwd+FRGzgceGNmbmv1UVlCRJ6m9lEpRvAucBNwLLqg1HkiSNVC9OdV8mQZmYmYdXHokkSVKhTILyvxGxQ2beXHk0kiRpxMZ1OoAKlElQdgauj4jf8eQ+KDtXFpUkSeprZRKU91YehSRJGrW+7IOSmT8HiIgpmXlf9SFJkqR+17LZKiKeHxF/oTGKh4iYERGzKo9MkiSVEm1c2qVMv5rPA68A7gfIzOuBF1UZlCRJ6m9lhxnfukL71uKK4pEkSSPUi31QVllBiYjTipuPR8TaQBbbt6VpNI8kSdJYG66CsmPx80TgEmCTiDgT2Bs4uOK4JElSSX05D0pmXhgRvwX2KjZ9IjNvrzYsSZLUz4ZLUHaIiIVN60MNXB+PCDJzowrjkiRJJfViH5ThEpTfA/u0KxBJkqQhwyUoj2fmX9oWiSRJUmG4BMWhxJIk1UDvNfAM0/E3M3dpZyCSJElDykzUJkmSulgP9pHtyaHTkiSp5qygSJJUc+N6sBeKFRRJktR1rKBIklRz9kGRJElqAysokiTVXNgHRZIkqXpWUCRJqjn7oEiSJLWBFRRJkmrOeVAkSZLawAqKJEk1Zx8USZKkNjBBkSRJXccmHkmSas4mHkmSpDawgiJJUs051b0kSVIbmKBIklRz46J9SysRcXpELIyIuU3bNoiISyPiD8XP9Vs+p9X7lUiSJD3JmcDeK2w7CrgsM7cCLivWh2WCIklSzUUb/7WSmVcBf1th82uAs4rbZwH7tTqOCYokSaraYGbOL27fCwy2eoCjeCRJqrl2zoMSETOBmU2bZmXmrLKPz8yMiGy1nwmKJEkqrUhGSickhQURMTUz50fEVGBhqwfYxCNJUs11Ux+UVTgPOKS4fQjw41YPMEGRJEljJiK+C/wS2Doi7oqIw4CTgD0j4g/Ay4r1YdnEI0lSzZWZn6RdMvOgVdy1x0iOYwVFkiR1HSsokiTVnN/FI0mS1AYmKJIkqevYxCNJUs21c6K2drGCIkmSuo4VFEmSaq4HCyhWUCRJUvexgiJJUs2N68FOKFZQJElS16m8grLo8aVVn0IVmryGRba62nzK5E6HIKlNeq9+YgVFkiR1IT8eS5JUdz1YQrGCIkmSuo4VFEmSas4vC5QkSWoDKyiSJNVcD06DYgVFkiR1HysokiTVXA8WUKygSJKk7mOCIkmSuo5NPJIk1V0PtvFYQZEkSV3HCookSTXnRG2SJEltYAVFkqSac6I2SZKkNrCCIklSzfVgAcUKiiRJ6j5WUCRJqrseLKFYQZEkSV3HCookSTXnPCiSJEltYAVFkqSa6/t5UCJiYkRsXFUwkiRJUCJBiYjvRcS6EbEmMBe4NSI+UH1okiSpjGjj0i5lKihbZ+Y/gH2By4FNgbdUGpUkSeprZRKUCcXPlwIXZuYjwPLqQpIkSf2uTCfZWyPiImAb4KiiqUeSJHWLHuwkWyZBOQTYC7gpMxdFxCbAUdWGJUmS+lnLBCUzHwV+VIzgWQv4O3BV5ZFJkqRS+nKitoh4XUTcCTwKPAQ8XPyUJEmqRJkmns8A+wM3ZKadYyVJ6jK9OFFbmQRlfmb+uvJIJEmSCmUSlC9HxCeAHwKPDW3MzFsri0qSJJXWgwWUUgnKJsD7aYzmWVZsS2CLqoKSJEn9rUyC8h5gembOrzoYSZI0Cj1YQikzk+xfTE4kSVI7lamgXBcR3wW+z5P7oFxYWVSSJKm0XpwHpUyCslPx891N2xIwQZEkSZUoM5Psbu0IRJIkjU4vzoNSZibZiIjDIuKkYn2ziHhh9aFJkqR+VaaT7OeBPYD9ivWHgP9XUTySJGmEoo1Lu5RJUHYD3kTju3jIzL8Ck6oMSpIk9bcynWQfy8yMooErIsbRkyOuJUmqqR58Vy5TQbk5It5EozvKZsDJwNWVRiVJkvpamQTl/cCuwFTgV8VjPlRhTJIkqc+VGWb8EPC2YpEkSV2mryZqi4h9hnugM8lKkqSqDFdB+eAw9zmTrCRJXaIXJ2pbZYLiDLKSJKlTygwzHmru2b1YvSwzL6ouJEmSNBI9WEApNdX9CcBJwN+K5b8i4hNVByZJkvpXZObwO0T8HtgxMxcV65OB32TmM8qc4K+Llg5/AnW1yWuUKrJJkppMGmhvUeP3Cx5p23vtMwbXastzKzMPyt+BR5rWHyu2SZIkVaLMMONfABdFxFnF+puBa6oOTJIkldNX86Dwz8OMZzbd3rGCWCRJUs1FxB3AQ8AyYGlmzhjNcRxmLElSzXXhPCi7Zeb9q3OAssOM9wJeVqxekpmXrs5JJUmShlNmmPEHgc8BDxTL5yPiA9WGJUmSyoo2LiUkcElE3BARM1vuvQplKigHAy8ovjSQiPgScC3w2dGeVJIk1VORdDQnHrMyc1bT+osz8+6I2Ai4NCJ+m5lXjfQ8ZRKUGEpOoPHtxhFd2NolSVK/auO7cpGMzBrm/ruLnwsj4ofAzsCIE5Qy86D8OiLOiIgXFstpwPUjPZEkSeptETE5ItYZug28HJg7mmOVSVDeDSwAvlQs9wGHj+ZkvWTBvfM5fOahvPF1r+JNB7ya//nOtzodkkbg2quv4tX77sUr996T005d5QcBdSmvX3157XreIHBNRNwEXAdckJkXj+ZAwzbxRMR44P9l5ttGc/BeNn78AO9+34fYepttWbRoEf/xpgPZeZcXsPkW0zsdmlpYtmwZJ55wPKecegaDg4O88fUHsOtuu7PldK9dHXj96strV51umagtM/8EPHssjjVsBSUzlwHPGosT9ZoNp0xh6222BWDy5Mk8ffMtuG/hwg5HpTLm3jyHadOezqbTpjFh4kT23mdfrrzisk6HpZK8fvXltdNIlGniuTwivhIRO0fEtkNL5ZHVyPx77uYPv7uN7bY3l6uDhQsWsPHUjZ9Y32hwkAULFnQwIo2E16++vHbViWjf0i5lRvG8ofi5b9O2BLYY+3Dq55FHFnH0B47gvUcexeS11+50OJIk9YSWFZTM3Hwly7DJSUTMjIjrI+L6s04/deyi7TJLlyzh6A8cwcv32Zdd99iz0+GopI0GB7l3/r1PrC9csIDBwcEORqSR8PrVl9euOl02UduYKNPEQ0RsHxGHF0vL5p3MnJWZMzJzxiH/0Zv9azOTE48/ls0234KD3nxop8PRCGy3/Q7Mm3cHd911J0sWL+biCy/gpbvt3umwVJLXr768dhqJlk08EfGfwNHABcWmoyLihMw8udLIutyc2Tdy8QXnseX0Z3DIG/YH4O2HH8ELX/ySDkemVgYGBvjIMcfyzplvZfnyZez32tcxffpWnQ5LJXn96strV6HuGMQzpiIzh98h4vc0pq1dWKxPAa7NzGeUOcFfFy0d/gTqapPXKPV9kpKkJpMG2psy3PHXx9r2XrvZUye15bmVefd5cCg5AcjM+yLiwQpjkiRJI9At86CMpTIJyqUR8Q3gtGL9UOCnQ31RMvPWimKTJEl9qkwTz5+HuTtbjeixiafebOKRpJFrdxPPvL893rb32n/ZYI3uaOLJzM3bEYgkSdIQPx5LklRzvdcDpeQ8KJIkSe1kBUWSpJpr53fktIsVFEmS1HVaJigR8bmIWDciBiLi6ohYFBFvbkdwkiSpP5WpoLwsM/8B7AXcDWwFfKDSqCRJ0gj03tcFjqSJ5yXAuZl5D+DcJpIkqTJlOskujIiTgVcAJ0XEADC+2rAkSVJZ/dpJ9o3A74A3ZObfgU2Bz1calSRJ6mstp7pfXU51X29OdS9JI9fuqe7veWBx295rn7bexO6Y6j4i7mMlfU4yc6NKIpIkSX2vzMfjGU23JwFvApZUE44kSRqpXuyDMqomnoj438zcpcy+NvHUm008kjRy7W7imf+P9jXxTF23S5p4VhQRWwA270iS1CWiB78ucKR9UMYBE4D3VhmUJEnqbyPtg7IUuDczl1UUjyRJGqneK6C0TlAy8y/tCESSJGnIKhOUVQ0vppGnpcOMJUnqDj1YQBm2gjJjmPskSZIqs8oEZahpJyLeAJyTmUvbFpUkSSqtF+dBKfNdPAcBd0TE8RGxSdUBSZIktUxQMvM1wIuBicD1EfH9iNit8sgkSVLfGtFMshHxQuB7wPrAn4H/zMyrh3uMM8nWmzPJStLItXsm2fseat977ZR1BrpjJtmImAi8HngXMB74KI0kZWfgv4HNKoxPkiT1oTIfj+8ArgTen5m/bNp+TUT8rIqgJEnSCPRgJ9kyCcpOmTm/eUNEPCUzH8zMt1YUlyRJ6mNlRvFcsJJtV45xHJIkaZSijUu7DDeT7ACNkTvjImJN/i+udYG12hCbJEnqU8M18RwDfIzGdPeLmrY/CHyuyqAkSVJ5vThRW8thxhHxlcw8fLQncJhxvTnMWJJGrt3DjNv5XvvUyV0yzHgoOYmI9YBdgT9l5pxqw5IkSWVFDw7jWWUn2Yj474h4dnF7A+Bm4ATg0ohw9I4kSarMcKN4npuZNxW3DwZuy8ztgJ2AUTf5SJKksRXRvqVdhktQHmu6/WLghwCZeReNjrOSJEmVGHYelIh4WjHEeFfg5013TaoyKEmS1N+G6yT7X8BsYDFwTWbeChARuwDzqg9NkiT1q2GHGUfExsDGwE1Z7BgRTwMGMrNUkuIw43pzmLEkjVy7hxk/8Oiytr3Xrrfm+M4PM87Me4F7V9h2T6URSZKkvlfmu3gkSZLayvq9JEk111cTtUmSJHWKFRRJkmquF78s0AqKJEnqOlZQJEmquR4soFhBkSRJ3ccKiiRJddeDJRQrKJIkqetYQZEkqeacB0WSJKkNrKBIklRzzoMiSZLUBlZQJEmquR4soFhBkSRJ3ccKiiRJddeDJRQrKJIkqeuYoEiSpK5jgiJJUs1FG/+1jCVi74j4XUT8MSKOGu1zMkGRJEljIiLGA18FXgFsCxwUEduO5lh2kpUkqea6aKK2nYE/ZuafACLie8BrgFtHeiArKJIkaaxsAtzZtH5XsW3EKq+gPHXyQPfkdRWIiJmZOavTcWh0vH715bWrN6/f2Jo00L6BxhExE5jZtGlWFdfSCsrqm9l6F3Uxr199ee3qzetXU5k5KzNnNC3NycndwLSm9U2LbSNmgiJJksbKr4GtImLziJgIvAE4bzQHspOsJEkaE5m5NCIOB34KjAdOz8xbRnMsE5TVZxtqvXn96strV29evx6VmRcCF67ucSIzxyAcSZKksWMfFEmS1HX6IkGJiDUi4nMRcXtE/DYiZkfEgRWd64iI2Khp/R0R8b4qztWvIuKO4jreFBG3RcRbV+NYXp8xEhG/Kv62bo2IpcXt2RFxRoXnPC4iPltiv/0iYueq4ugGEXFgRPym+J3/NiK+03TfcUWHxVbH2Cwi7q820pGLiCsj4pUjvU/11i99UL4GrA1sl5mPRcT2wE8j4m+ZedkYn+sI4GfAQoDM/PoYH18NB2Tm3OJa3hgRF2bmPSM9iNdn7GTm86HxJgdcn5nP6WhAT7YfcD1wXYfjqERETKXxOvfczLwzIgJ4TtMuHwM+CyzuQHgtRcRAZi7tdBzqLj1fQYmIpwOvB96ZmY8BZOZc4JPAx1b8BNa8HhETI+IzEXFd8Wn9WxGxdnHfzOLT++yImBMRz4yIY4CnAecU27dd4XjjI+KzETG3WD5bfG8BEXFmRHw9Ii6PiD9ExDeLFxkNo7iWfwc2iYitI+KiiPh1cb3+HSAiPhoRXxh6TEQ8NSLuj4jJK7n+Hy6u940R8ZOI2LjYfvdQZSwiLoyIC4rbG0XEXe18znUSEftExLURcUNE/DIidim271pco1Mj4ubi971dRJxdVGB+GhGTi32PK7ZfXlQGfhAR667kXDtExNXFsW6NiCOK7XsBrwaOKv4u31JsP6So+txQHHvrYvsLi2PMjohbIuKgNv26VsfGwBLgrwDZ8BuAiPhqsc8viuf0tIiYHxGThh4cEedFxBubD7hiNaV5vfh//7Pi2t3c/Pe1wjHuiIiTit/xH6MxumPF+64DTomItSPijKbXxw+tcLiXFX+bf4yIE1dxvqdExDeK/eZExBebXmOvjEYl/eqIuDMiPhARB0XEL4pYDiz2Wysivl/8H7opIs4u8ftXFTKzpxfglcDslWzfkcYb23HAZ5u2P7EOfBT4aNN9nwJOKG7/A5ha3F4DWKu4fQew/SqO904a1ZWJxXIZjcQJ4EzgGmBScd8twJ6d/v1149L8OwZeVPyuJgI3AM8stq8D/A54JvAvwHxgoLjv3TSGvq14fd5MY2TBuKbr9e3i9n/TGM8/AbiNxvdKTAAOAr7V6d9JNy3AZsD9wJbAL4GnFNu3A+YVt3el8Yb6nGL9qzSmxN60WL8QeGvTNZoPDBbrpzdds+brtw6wRnF77eIabVOsnwkc3hTjvwIXNO3/CuDa4vaPgYOK2wGs1+nfaYnf+TjgR8Xv/RwaldynNt2fwNpN698DDmm6XvcUf0ObAfc3X8cVr2tx+33AKU33rb+KuO5o+lsbLM7zrKb7vta076eAs4rf+VNo/F2/orjvSuASGlX/tYGbgVc23Td0+xvAwU2/k+8Cb2va73+K7U8DHuH/Xs93Bu4qbr8W+Gmr5+ZS/dIPTTzDVSFaDWF6NfCUiDigWF8DuKm4fTlwVkT8BLggiy9GauFlwJmZuRggGm3zrwVOLu7/URZVnoi4kcYL/KUljtuPzikqTNOBA4uf2wDfayo8rUHjDeqHEXELsA+NCYMOpfECu6JXAzNoNBlB48XwH8V9l9G4fncD/0vj/9Xzi22Xj/Fz6xV70fg/fFXTNRmIiMHi9u8yc3Zx+0bg6Zk5VI26gcY1HXJ+Zi4obp8GfHkl51sLODking0sp/Em9GwaCeWKXlXc96sitgDWL+67AvhoRGwJXJqZvyr3dDsnM5cD+0WjyfOlNJq0PhgRO2Tm31bykC8BX6CRELyDRhKxOMoXbf8XeF9EfAb4OY05L1bltCLGBUXlcVdgTnHfN5v2exnw3mxkBQ9GxHeLbRcV95+VjWagh6PxBXS7A+evcK5XAztHxJHF+lo0Et8h3y9+V/dExF+BHxbbb6BRhZ1E4zV+m6LydCWNRFYd0A8Jys3A9IjYYIU/1F2AXwBLeXJT16Sm2wG8KzNX9ga0P/A8Gn8kV0TEOzLzopXsNxKPNd1eRn9cn9Ea6oNyIHAGjRem+3PV/R7OBA6JiD8D6wJXr2SfAD6Zmaev5L7LgWNpvNhdVuy7R7F8fDWeRy8L4OLMfMs/3RGxDf/8/33F9TVHeL4TgXuBQ7MxWdQlPPnvecXYTs/MY1e8IzP/X/HB42XAlyPiksz86Ahj6YhsNHnOBb4aEbfSSAbOXcl+v4hGk/OLaCTsz1vJ4Vb52piZv4yIHYE9gYOBo4AXjyLkh0fxmOEEsN8wHxhX+n8uM5cNfSjJzD9FxHY0/rZfAZxYJHqP/dPRVKme74OSmXcA36fxyWoSQPEp4300mnD+COwUEeMiYh0aTUJDzgPeHxFrFo9bJyK2iYgBYIvMvC4zT6JRetyxeMyDNN4AV+ZnNN4kJ0TEBOAQrJCslsz8Po3f/4HAIxFx8NB90egX9JRi9VzgJcCRNKpYK6uenQe8KyLWLx6/RvFpnMz8C40XtENoJCiX0XhhX5KZ86p4bj3gEmDv4sUegIhY2RthGftGxJTi9r+z8qrVesCdRXKyPY1mnCEr/l3+BHhLRGxaxDU+InYqbj8jM2/PzFOAL9Io/3e1iNgkIl7QtL4pMAX4c7HpIf75denLNJp6fpGZd/LP7gUmRMRQJeuJPioRsTnwYGZ+D3g/xWvoKsI7tHjMFBpVzCtWsd/PgMOiYR0aTarNr49vjoiBaPRN+jdW/n/gPBp9jYb6nWxYxFpa8btblpk/ovE+MQXYYCTH0Njol0/o76Lx6erWiEgaX/28S2bOLj5lvJ5GGXgejVLfkJNotHH/OiKW02gS+jjwJ+DMiFiPRin5ThqfIKBROj0jIh6h6Q+6MItG2fo3xfpPgVPH7mn2rY/QuG6vpPHi9EEaUywvoPFCRmY+EhE/pvHmttIXrMz8VkRsCPy8+DQ1jsbIiKFmvcuAF2fmfICIeJSVV2IEZOYfIuLNwGlFkj8RuJbGd3WM1NU0mu82odG35MiV7PNJ4FsRcRjwe+Cqpvu+ReNv9kDg85n5zWh0aj+veDObSOODzA3AeyJiNxojXh6n0Wep2w0AH4/GoIBHafzf/WgWHWWBzwGXF/9nd83MB2gkJ1+l8X/8nxSJ3nuBSyPiPp7c1LErjQ9vy4pzvaNoOlmZ+yPiBhoJ0n9l5s2r2O8TwFdoVL2h0bfr4qb7f0uj6r0BcHZmrti8A42+N58Gbipe6x8vtv15Jfuuyg7AScVrwPgi5hGPENTq67uZZIvKxSk0vm3xVZbtpO4WEcfR6OD5gU7H0ksi4sXA14EdVlFRHItz3EGjA+vcKo6v3tYvFZQnZOYS4D86HYckdUpEnEaj/8hbqkpOpNXVdxUUSZLU/Xq+k6wkSaofExRJktR1TFAkSVLXMUGRJEldxwRFkiR1HRMUSZLUdf4/INbwmNQ40oQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "ax.set_xticklabels(labels,fontsize=11)\n",
    "ax.set_yticklabels(labels,fontsize=11);\n",
    "#plt.xlabel('Predicted')\n",
    "#plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing Model to Hugging Face Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5Model' object has no attribute 'push_to_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1x/hvb1q6g96_qgcywwm07fmxhc0000gn/T/ipykernel_50515/1670482929.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my-awesome-model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"api_PKetuiPRMMMERwpYBsgdQcIAAuODMgkuiF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'T5Model' object has no attribute 'push_to_hub'"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"my-awesome-model\", use_auth_token=\"api_PKetuiPRMMMERwpYBsgdQcIAAuODMgkuiF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manningLp",
   "language": "python",
   "name": "manninglp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
